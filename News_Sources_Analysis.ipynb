{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "News Sources Analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OmarMeriwani/Fake-Financial-News-Detection/blob/master/News_Sources_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxnMFRW7SlPQ",
        "colab_type": "text"
      },
      "source": [
        "# News Sources Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCTFZ5XLSlUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-cSzbZlSlaS",
        "colab_type": "text"
      },
      "source": [
        "Note that it is required to download the dataset train.csv from the [link](https://www.kaggle.com/c/fake-news), the other dataset Resources.csv already exists in the path. If kaggle dataset is in use, then set the kaggle parameter to true to change the other steps accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0em1GluZSlgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('Kaggle Competition/train.csv',header=0)\n",
        "data = []\n",
        "labels = []\n",
        "prev = ''\n",
        "kaggle = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeo9TsweSllO",
        "colab_type": "text"
      },
      "source": [
        "Sources are semi-colon separated in Resources.csv dataset, while there is only one resource in kaggle train.csv dataset but there is a larger number of records. Sources are lowercased and added into the array (data) in this step, while labels are stored in labels array. Labels in kaggle dataset are written as 0 and 1, while they are written as true and false in the Resources dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqKo69s0SlrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0,len(df)):\n",
        "    #claim,label,date,sources\n",
        "    #sources =  str(df.loc[i][1]).replace('www','').replace('.','').split(';')\n",
        "    #Kaggle\n",
        "    sources =  str(df.loc[i][2]).replace(' ','')\n",
        "    sources2 = []\n",
        "    for s in sources:\n",
        "        if s == '':\n",
        "            continue\n",
        "        else:\n",
        "            sources2.append(s)\n",
        "    if sources2 == []:\n",
        "        continue\n",
        "    if kaggle == False:\n",
        "        sources = ' '.join(sources2)\n",
        "    label = df.loc[i][4]\n",
        "    if kaggle == False:\n",
        "        if str(label).lower()== 'true':\n",
        "            label = 1\n",
        "        else:\n",
        "            label = 0\n",
        "    data.append(sources)\n",
        "    labels.append(label)\n",
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L_gPGlLSlwa",
        "colab_type": "text"
      },
      "source": [
        "Splitting training and testing datasets, and fitting the Tfidf Vectorizer to create vector representations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE2sf81USl2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(data,labels,test_size=0.4)\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "_ = tfidf.fit(x_train)\n",
        "train_tfidf = tfidf.transform(x_train)\n",
        "test_tfidf = tfidf.transform(x_test)\n",
        "print ('Transforming final test dataset')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M8bkx8eSl7g",
        "colab_type": "text"
      },
      "source": [
        "Classifier, training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G466xQGYSmAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = MLPClassifier(hidden_layer_sizes = (20,20,20), solver ='lbfgs', random_state=50)\n",
        "model1.fit(train_tfidf,y_train)\n",
        "print(model1.score(test_tfidf,y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}