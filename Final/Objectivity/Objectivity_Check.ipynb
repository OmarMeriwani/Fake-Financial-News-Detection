{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/OmarMeriwani/Fake-Financial-News-Detection/blob/master/News_Sources_Analysis_Objectivity_Check.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KpuHE2K0KEcg",
    "colab_type": "text"
   },
   "source": [
    "# News Sources Analysis - Objectivity Check\n",
    "This document combines the [feature of \"who said\"](https://github.com/OmarMeriwani/Fake-Financial-News-Detection/blob/master/News_Sources_Analysis_Who_Said.ipynb) with two other features to predict the fake news using the proposed objectivity check method. \n",
    "The libraries below are the one that are required for this file to run, they include libraries for evaluation, prediction and preprocessing methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Mf6hY7P3KEoW",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from nltk.stem.porter import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihJpLZmsKEt4",
    "colab_type": "text"
   },
   "source": [
    "Stanford core NLP method and two methods for verbs related features (previously explained in  [\"Who Said\"](https://github.com/OmarMeriwani/Fake-Financial-News-Detection/blob/master/News_Sources_Analysis_Who_Said.ipynb) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "jyYG8Ia6KE0M",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "java_path = \"C:/Program Files/Java/jdk1.8.0_161/bin/java.exe\"\n",
    "os.environ['JAVAHOME'] = java_path\n",
    "host='http://localhost'\n",
    "port=9000\n",
    "scnlp =StanfordCoreNLP(host, port=port,lang='en', timeout=30000)\n",
    "stemmer = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "1vsAuLqIKFAD",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def getVerbs(verb):\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(verb):\n",
    "        for l in syn.lemmas():\n",
    "            synonyms.append(l.name())\n",
    "    return set(synonyms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "sE3UDrI-KFLK",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def WhoSaid (sent, verb):\n",
    "    result = []\n",
    "    deps = scnlp.dependency_parse(sent)\n",
    "    tags = scnlp.pos_tag(sent)\n",
    "    ners = scnlp.ner(sent)\n",
    "    verbindex = []\n",
    "    for i in range(1, len(tags)):\n",
    "        if tags[i][0] == verb:\n",
    "            verbindex .append( i + 1)\n",
    "    for i in deps:\n",
    "        if i[1] in verbindex and i[0] == 'nsubj':\n",
    "            result.append([tags[i[2] - 1][0], tags[i[2] - 1][1], ners[i[2] - 1][1] ])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_lxC_WpKFQ2",
    "colab_type": "text"
   },
   "source": [
    "The same features explained  [previously](https://github.com/OmarMeriwani/Fake-Financial-News-Detection/blob/master/News_Sources_Analysis_Who_Said.ipynb)  are presented here, but using another dataset for evaluation, and with using new features for getting named entities and time expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Y8KGr79bKFWa",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "features = []\n",
    "df = pd.read_csv('../Sentiments/FakeNewsSA.csv')\n",
    "for i in range(0,len(df)):\n",
    "    claim = df.loc[i][0]\n",
    "    label = df.loc[i][1]\n",
    "    lemTags = scnlp.pos_tag(claim)\n",
    "    colonAvailable = 1 if (claim.find(':') != -1) else 0\n",
    "    tags = scnlp.pos_tag(claim)\n",
    "    tagsarr = []\n",
    "    sayverbs = getVerbs('say')\n",
    "    isSayVerb = 0\n",
    "    isNPPSaid = 0\n",
    "    isNERSaid = 0\n",
    "    isQuestion = 0\n",
    "    nnpfound = 0\n",
    "    if '?' in claim:\n",
    "        isQuestion = 1\n",
    "    nnp_followed_by_colon = 0\n",
    "    mid = int((len(tags) - 1) / 2)\n",
    "    for t in lemTags:\n",
    "        verb = stemmer.stem(str(t[0]).lower())\n",
    "        if 'V' in t[1]:\n",
    "            for j in sayverbs:\n",
    "\n",
    "                if verb == str(j).lower():\n",
    "                    whosaid = WhoSaid(claim, str(t[0]))\n",
    "                    if whosaid != []:\n",
    "                        for w in whosaid:\n",
    "                            if w[1] == 'NNP' and isNPPSaid == 0:\n",
    "                                isNPPSaid = 1\n",
    "                            if w[2] != 'O' and isNERSaid == 0:\n",
    "                                isNERSaid = 1\n",
    "                        print('Whosaid', whosaid)\n",
    "                    isSayVerb = 1\n",
    "                    break\n",
    "    for i in range(0, mid):\n",
    "        word = tags[i][1]\n",
    "        if nnpfound == 1 and word == ':':\n",
    "            nnp_followed_by_colon = 1\n",
    "            break\n",
    "        if word == 'NNP':\n",
    "            nnpfound = 1\n",
    "        else:\n",
    "            nnpfound = 0\n",
    "    nnp_preceeded_by_colon = 0\n",
    "    for i in range(0, mid):\n",
    "        word = tags[len(tags) - 1 - i][1]\n",
    "        word2 = tags[len(tags) - 1 - i][0]\n",
    "        if word == 'NNP':\n",
    "            nnpfound = 1\n",
    "        if nnpfound == 1 and word == ':':\n",
    "            nnp_preceeded_by_colon = 1\n",
    "            break\n",
    "        if word != 'NNP':\n",
    "            nnpfound = 0\n",
    "    numberOfNER = 0\n",
    "    usingTimeExpressions = 0\n",
    "    features.append([colonAvailable, nnp_followed_by_colon, nnp_preceeded_by_colon, isNPPSaid, isNERSaid, isQuestion])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SLF5yo6KFb9",
    "colab_type": "text"
   },
   "source": [
    "Using the stored model of WhoSaid to predict the referral feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "NmyBeoRWKFhe",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "mlp = pickle.load(open('WhoSaid.pkl', 'rb'))\n",
    "y= mlp.predict(features)\n",
    "features2 = []\n",
    "labels = []\n",
    "for i in range(0, len(features)):\n",
    "    claim = df.loc[i][0]\n",
    "    Cited = y[i]\n",
    "    label = df.loc[i][1]\n",
    "    numberOfNER = 0\n",
    "    usingTimeExpressions = 0\n",
    "    '''\n",
    "    NEW ADDITION, NOT PRESENTED IN WHO SAID SOURCE CODE\n",
    "    The code below performs a named entity recognition feature on the claim, and checks whether it contains time expressions and / or named entities\n",
    "    '''\n",
    "\n",
    "    for tag in scnlp.ner(claim):\n",
    "        if tag[1] != 'O':\n",
    "            numberOfNER += 1\n",
    "        if tag[1] == 'DATE' and usingTimeExpressions == 0:\n",
    "            usingTimeExpressions = 1\n",
    "    print(claim, numberOfNER, usingTimeExpressions, label)\n",
    "    features2.append([ numberOfNER, usingTimeExpressions])\n",
    "    labels.append(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwQ7zqr0KFnZ",
    "colab_type": "text"
   },
   "source": [
    "Evaluation using accuracy, precision, recall, F1 score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "4_mhmBHbKFtS",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(features2, labels)\n",
    "mlp2 = MLPClassifier()\n",
    "max = 0\n",
    "for i in range(0,100):\n",
    "    mlp2.fit(xtrain,ytrain)\n",
    "    score = mlp2.score(xtest, ytest)\n",
    "    if score > max:\n",
    "        max = score\n",
    "        print('Accuracy: ',score)\n",
    "        yhat_classes = mlp2.predict(xtest)\n",
    "        #yhat_classes = yhat_classes[:, 0]\n",
    "        # precision tp / (tp + fp)\n",
    "        precision = precision_score(ytest, yhat_classes)\n",
    "        print('Precision: %f' % precision)\n",
    "        # recall: tp / (tp + fn)\n",
    "        recall = recall_score(ytest, yhat_classes)\n",
    "        print('Recall: %f' % recall)\n",
    "        # f1: 2 tp / (2 tp + fp + fn)\n",
    "        f1 = f1_score(ytest, yhat_classes)\n",
    "        print('F1 score: %f' % f1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "News Sources Analysis - Objectivity Check",
   "version": "0.3.2",
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
